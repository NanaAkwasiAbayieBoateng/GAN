{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as tutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(root='./data',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "# Data loader\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    IS_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var(x):\n",
    "    if IS_CUDA:\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "# Reference: https://github.com/pytorch/vision/blob/master/test/sanity_checks.ipynb\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "trans = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: standard model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim = 400, z_dim = 20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim*2))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        epsilon = var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + epsilon * torch.exp(log_var/2)\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim = 1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "vae = VAE()\n",
    "if IS_CUDA:\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: New Layer for Mean and Variance\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim = 400, z_dim = 20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.MuExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, z_dim),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.SigmaExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, z_dim),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        epsilon = var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + epsilon * torch.exp(log_var/2)\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.MuExtractor(h)\n",
    "        log_var = self.SigmaExtractor(h)\n",
    "        # mu, log_var = torch.chunk(h, 2, dim = 1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "vae = VAE()\n",
    "if IS_CUDA:\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Drop Mu size by Half and skip earlier middle layer\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim = 400, z_dim = 20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim/2, z_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.MuExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, z_dim/2),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.SigmaExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, z_dim/2),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        epsilon = var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + epsilon * torch.exp(log_var/2)\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.MuExtractor(h)\n",
    "        log_var = self.SigmaExtractor(h)\n",
    "        # mu, log_var = torch.chunk(h, 2, dim = 1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "vae = VAE()\n",
    "if IS_CUDA:\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Get single value for Mean and Variance\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim = 400, z_dim = 20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, z_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(z_dim, image_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.MuExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.SigmaExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        epsilon = var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + epsilon * torch.exp(log_var/2)\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.MuExtractor(h)\n",
    "        log_var = self.SigmaExtractor(h)\n",
    "        # mu, log_var = torch.chunk(h, 2, dim = 1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "vae = VAE()\n",
    "if IS_CUDA:\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: Drop Mean and Variance to 10\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim = 400, z_dim = 20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(h_dim, z_dim))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, z_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(z_dim, image_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        self.MuExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, 10))\n",
    "            #nn.Sigmoid())\n",
    "        \n",
    "        self.SigmaExtractor = nn.Sequential(\n",
    "            nn.Linear(z_dim, 10))\n",
    "            #nn.Sigmoid())\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        epsilon = var(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + epsilon * torch.exp(log_var/2)\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.MuExtractor(h)\n",
    "        log_var = self.SigmaExtractor(h)\n",
    "        # mu, log_var = torch.chunk(h, 2, dim = 1)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, log_var\n",
    "    \n",
    "    def sample(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "vae = VAE()\n",
    "if IS_CUDA:\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data_loader)\n",
    "fixed_x,_ = next(data_iter)\n",
    "torchvision.utils.save_image(fixed_x.cpu(), './data/real_images.png')\n",
    "fixed_x = var(fixed_x.view(fixed_x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "# os.mkdir('./data/genImg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(outputImages, modelName):\n",
    "    path = './data/genImg/'+modelName\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in data_loader:\n",
    "            img, _ = data\n",
    "            img = var(img.view(img.size(0), -1))\n",
    "            out, mu, log_var = vae(img)\n",
    "            rc_loss = F.binary_cross_entropy(out, img, size_average=False)\n",
    "            KL_div = torch.sum(0.5 * (mu ** 2 + torch.exp(log_var) - log_var - 1))\n",
    "\n",
    "            total_loss = rc_loss + KL_div\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print 'Epoch [{}/{}], Loss {:.4f}, Entropy: {:.4f}, KL: {: .4f} '.format(epoch+1, num_epochs, total_loss.data[0], rc_loss.data[0], KL_div.data[0])\n",
    "        pic, _, _ = vae(fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, 28, 28) \n",
    "        outputImages += [trans(pic)]\n",
    "        torchvision.utils.save_image(pic.data.cpu(), path+'/image_{}.png'.format(epoch))\n",
    "        show(tutils.make_grid(outputImages))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAAD8CAYAAADNEc7HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4EVSSPAiKSR4kRQSvEgKCV4kxf8DxghyxOnBA3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe284eca5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = data_iter.next()\n",
    "img,_ = data_iter.next()\n",
    "pic = img.view(img.size(0), 1, 28, 28)\n",
    "imgList = [pic, pic, pic]\n",
    "#show(torchvision.utils.make_grid(imgList, padding=100))\n",
    "show(torchvision.utils.make_grid(img, padding=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-056e21b11961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3081\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5192\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5194\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5195\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    602\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    603\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNYZBUmMYJDWGQVJjGCQ1/wMKpFHVdp3xCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe290d90850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "grid = [torchvision.utils.make_grid(img).numpy().transpose((1, 2, 0))] * 3\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test():\n",
    "    i = 0\n",
    "    outputImages = []\n",
    "    labels = []\n",
    "    for data in test_data_loader:\n",
    "        img, label = data\n",
    "        img = var(img.view(img.size(0), -1))\n",
    "        out, mu, log_var = vae(img)\n",
    "        rc_loss = F.binary_cross_entropy(out, img, size_average=False)\n",
    "        KL_div = torch.sum(0.5 * (mu ** 2 + torch.exp(log_var) - log_var - 1))\n",
    "\n",
    "        total_loss = rc_loss + KL_div\n",
    "        i += 1\n",
    "        print i, ' Loss {:.4f}, Entropy: {:.4f}, KL: {: .4f} '.format(total_loss.data[0], rc_loss.data[0], KL_div.data[0])\n",
    "        pic, _, _ = vae(fixed_x)\n",
    "        pic = pic.view(pic.size(0), 1, 28, 28) \n",
    "        outputImages.append((out.data).cpu().numpy())\n",
    "        labels.append(label)\n",
    "        \n",
    "    return outputImages, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 10979.6230, Entropy: 8425.0947, KL:  2554.5286 \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "img should be PIL Image. Got <class 'torch.autograd.variable.Variable'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c61e09f03d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutputImages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ExtractFromLayer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-184a23669c2e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(outputImages, modelName)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputImages\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/image_{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \"\"\"\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bhushan/anaconda3/envs/py27/lib/python2.7/site-packages/torchvision-0.2.0-py2.7.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: img should be PIL Image. Got <class 'torch.autograd.variable.Variable'>"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "outputImages = []\n",
    "train(outputImages, 'ExtractFromLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  Loss 10230.0762, Entropy: 7683.6147, KL:  2546.4614 \n",
      "2  Loss 10663.1680, Entropy: 8070.4014, KL:  2592.7671 \n",
      "3  Loss 10300.2285, Entropy: 7728.0835, KL:  2572.1445 \n",
      "4  Loss 9814.8135, Entropy: 7330.0122, KL:  2484.8013 \n",
      "5  Loss 10073.9727, Entropy: 7487.5088, KL:  2586.4639 \n",
      "6  Loss 10463.7324, Entropy: 7845.9434, KL:  2617.7886 \n",
      "7  Loss 10432.4199, Entropy: 7829.6670, KL:  2602.7529 \n",
      "8  Loss 10131.3926, Entropy: 7623.0684, KL:  2508.3245 \n",
      "9  Loss 10031.3066, Entropy: 7550.1870, KL:  2481.1201 \n",
      "10  Loss 9751.9102, Entropy: 7330.5024, KL:  2421.4080 \n",
      "11  Loss 9910.4756, Entropy: 7395.8696, KL:  2514.6057 \n",
      "12  Loss 10346.1104, Entropy: 7763.2529, KL:  2582.8572 \n",
      "13  Loss 10368.8975, Entropy: 7782.8101, KL:  2586.0872 \n",
      "14  Loss 10154.0918, Entropy: 7635.8120, KL:  2518.2798 \n",
      "15  Loss 9963.4238, Entropy: 7446.4580, KL:  2516.9656 \n",
      "16  Loss 9666.5293, Entropy: 7160.4912, KL:  2506.0381 \n",
      "17  Loss 10263.4014, Entropy: 7695.4229, KL:  2567.9783 \n",
      "18  Loss 9630.1650, Entropy: 7184.4604, KL:  2445.7046 \n",
      "19  Loss 10152.8330, Entropy: 7608.1343, KL:  2544.6987 \n",
      "20  Loss 10199.5508, Entropy: 7669.6221, KL:  2529.9282 \n",
      "21  Loss 10218.0234, Entropy: 7666.4595, KL:  2551.5640 \n",
      "22  Loss 10143.9424, Entropy: 7580.7437, KL:  2563.1990 \n",
      "23  Loss 9875.2871, Entropy: 7351.9663, KL:  2523.3203 \n",
      "24  Loss 10001.2949, Entropy: 7492.8560, KL:  2508.4385 \n",
      "25  Loss 9695.5742, Entropy: 7278.2100, KL:  2417.3647 \n",
      "26  Loss 10043.9775, Entropy: 7521.9463, KL:  2522.0312 \n",
      "27  Loss 10319.1748, Entropy: 7824.2075, KL:  2494.9670 \n",
      "28  Loss 10243.3857, Entropy: 7736.2383, KL:  2507.1475 \n",
      "29  Loss 10305.8789, Entropy: 7705.6621, KL:  2600.2163 \n",
      "30  Loss 10508.5371, Entropy: 7964.7490, KL:  2543.7876 \n",
      "31  Loss 10278.6641, Entropy: 7720.6494, KL:  2558.0149 \n",
      "32  Loss 10213.3242, Entropy: 7647.3125, KL:  2566.0120 \n",
      "33  Loss 10107.9170, Entropy: 7542.3872, KL:  2565.5300 \n",
      "34  Loss 10415.0693, Entropy: 7853.0806, KL:  2561.9888 \n",
      "35  Loss 10140.4297, Entropy: 7615.8921, KL:  2524.5376 \n",
      "36  Loss 9797.3682, Entropy: 7293.3223, KL:  2504.0461 \n",
      "37  Loss 10432.5176, Entropy: 7832.1162, KL:  2600.4014 \n",
      "38  Loss 9952.3105, Entropy: 7448.3652, KL:  2503.9451 \n",
      "39  Loss 10487.7471, Entropy: 7909.2178, KL:  2578.5293 \n",
      "40  Loss 9917.7402, Entropy: 7382.5049, KL:  2535.2349 \n",
      "41  Loss 9769.7041, Entropy: 7275.0586, KL:  2494.6458 \n",
      "42  Loss 10164.0195, Entropy: 7652.0737, KL:  2511.9458 \n",
      "43  Loss 10751.2100, Entropy: 8142.1953, KL:  2609.0146 \n",
      "44  Loss 10476.5547, Entropy: 7876.0903, KL:  2600.4639 \n",
      "45  Loss 10126.0625, Entropy: 7580.4155, KL:  2545.6465 \n",
      "46  Loss 10372.9355, Entropy: 7788.2397, KL:  2584.6956 \n",
      "47  Loss 10005.9404, Entropy: 7479.1406, KL:  2526.7998 \n",
      "48  Loss 10225.9297, Entropy: 7677.3896, KL:  2548.5405 \n",
      "49  Loss 10175.8750, Entropy: 7600.0327, KL:  2575.8425 \n",
      "50  Loss 10103.3535, Entropy: 7539.9556, KL:  2563.3977 \n",
      "51  Loss 10088.7461, Entropy: 7592.3115, KL:  2496.4343 \n",
      "52  Loss 9782.1650, Entropy: 7268.5947, KL:  2513.5706 \n",
      "53  Loss 9983.3857, Entropy: 7425.2241, KL:  2558.1619 \n",
      "54  Loss 10230.1172, Entropy: 7702.2354, KL:  2527.8816 \n",
      "55  Loss 10347.8770, Entropy: 7732.9077, KL:  2614.9688 \n",
      "56  Loss 10217.2314, Entropy: 7635.5078, KL:  2581.7234 \n",
      "57  Loss 10579.8896, Entropy: 7986.8662, KL:  2593.0232 \n",
      "58  Loss 9964.0371, Entropy: 7495.5161, KL:  2468.5212 \n",
      "59  Loss 10648.9424, Entropy: 8029.2402, KL:  2619.7024 \n",
      "60  Loss 10533.8535, Entropy: 7925.3540, KL:  2608.5000 \n",
      "61  Loss 9547.5254, Entropy: 7121.1343, KL:  2426.3916 \n",
      "62  Loss 10352.1895, Entropy: 7788.2578, KL:  2563.9316 \n",
      "63  Loss 9893.9609, Entropy: 7422.4131, KL:  2471.5481 \n",
      "64  Loss 10064.6143, Entropy: 7555.6968, KL:  2508.9172 \n",
      "65  Loss 10021.1797, Entropy: 7497.9546, KL:  2523.2246 \n",
      "66  Loss 10501.7422, Entropy: 7894.4189, KL:  2607.3232 \n",
      "67  Loss 10353.5195, Entropy: 7759.6592, KL:  2593.8601 \n",
      "68  Loss 10483.4453, Entropy: 7904.1802, KL:  2579.2649 \n",
      "69  Loss 10377.0225, Entropy: 7807.4805, KL:  2569.5417 \n",
      "70  Loss 10051.5449, Entropy: 7526.0400, KL:  2525.5049 \n",
      "71  Loss 10195.9678, Entropy: 7657.5039, KL:  2538.4636 \n",
      "72  Loss 10317.8848, Entropy: 7747.8799, KL:  2570.0049 \n",
      "73  Loss 10126.1650, Entropy: 7569.2949, KL:  2556.8704 \n",
      "74  Loss 9537.3535, Entropy: 7118.1548, KL:  2419.1985 \n",
      "75  Loss 10479.9707, Entropy: 7866.8511, KL:  2613.1199 \n",
      "76  Loss 10469.3633, Entropy: 7893.0063, KL:  2576.3567 \n",
      "77  Loss 10353.0977, Entropy: 7767.0254, KL:  2586.0718 \n",
      "78  Loss 10234.5742, Entropy: 7684.9595, KL:  2549.6150 \n",
      "79  Loss 10095.0352, Entropy: 7549.3257, KL:  2545.7095 \n",
      "80  Loss 9898.6973, Entropy: 7410.8164, KL:  2487.8804 \n",
      "81  Loss 10350.4414, Entropy: 7749.4614, KL:  2600.9800 \n",
      "82  Loss 10129.5049, Entropy: 7594.3159, KL:  2535.1890 \n",
      "83  Loss 10138.8516, Entropy: 7603.1484, KL:  2535.7036 \n",
      "84  Loss 10331.7598, Entropy: 7706.4683, KL:  2625.2910 \n",
      "85  Loss 9959.8926, Entropy: 7448.8198, KL:  2511.0728 \n",
      "86  Loss 9880.3311, Entropy: 7379.3574, KL:  2500.9739 \n",
      "87  Loss 10634.5264, Entropy: 8030.3760, KL:  2604.1501 \n",
      "88  Loss 10223.5918, Entropy: 7667.9038, KL:  2555.6885 \n",
      "89  Loss 10283.8643, Entropy: 7712.5449, KL:  2571.3196 \n",
      "90  Loss 10208.2363, Entropy: 7608.4004, KL:  2599.8354 \n",
      "91  Loss 10056.9541, Entropy: 7551.5381, KL:  2505.4160 \n",
      "92  Loss 10012.5967, Entropy: 7485.8979, KL:  2526.6990 \n",
      "93  Loss 10477.2959, Entropy: 7892.9248, KL:  2584.3711 \n",
      "94  Loss 9607.6221, Entropy: 7151.5889, KL:  2456.0330 \n",
      "95  Loss 10267.1953, Entropy: 7759.4150, KL:  2507.7808 \n",
      "96  Loss 10416.0869, Entropy: 7907.2388, KL:  2508.8481 \n",
      "97  Loss 10116.0381, Entropy: 7579.7988, KL:  2536.2390 \n",
      "98  Loss 10675.3066, Entropy: 8068.1875, KL:  2607.1194 \n",
      "99  Loss 10173.3174, Entropy: 7648.3032, KL:  2525.0144 \n",
      "100  Loss 10515.2500, Entropy: 7893.1138, KL:  2622.1357 \n"
     ]
    }
   ],
   "source": [
    "predicted, labels = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npNum = np.array(predicted)\\nlNum = np.array(labels)\\nprint pNum.shape, lNum.shape\\n\\nx_test_encoded = pNum\\nplt.figure(figsize=(6, 6))\\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=lNum)\\nplt.colorbar()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "'''\n",
    "pNum = np.array(predicted)\n",
    "lNum = np.array(labels)\n",
    "print pNum.shape, lNum.shape\n",
    "\n",
    "x_test_encoded = pNum\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=lNum)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 18742.7168, Entropy: 18325.1270, KL:  417.5903 \n",
      "Epoch [2/10], Loss 18859.0566, Entropy: 18439.0176, KL:  420.0390 \n",
      "Epoch [3/10], Loss 17914.0098, Entropy: 17477.4941, KL:  436.5148 \n",
      "Epoch [4/10], Loss 19026.9043, Entropy: 18609.7520, KL:  417.1521 \n",
      "Epoch [5/10], Loss 18778.0293, Entropy: 18364.2324, KL:  413.7972 \n",
      "Epoch [6/10], Loss 18179.8105, Entropy: 17758.8984, KL:  420.9129 \n",
      "Epoch [7/10], Loss 18144.7070, Entropy: 17730.5508, KL:  414.1560 \n",
      "Epoch [8/10], Loss 18379.2988, Entropy: 17948.3750, KL:  430.9247 \n",
      "Epoch [9/10], Loss 19538.9688, Entropy: 19130.7754, KL:  408.1940 \n",
      "Epoch [10/10], Loss 19493.7598, Entropy: 19092.1016, KL:  401.6581 \n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "outputImages = []\n",
    "train(outputImages, 'SameSizeNNDiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 19722.6504, Entropy: 19512.7930, KL:  209.8571 \n",
      "Epoch [2/10], Loss 20034.1035, Entropy: 19819.8984, KL:  214.2052 \n",
      "Epoch [3/10], Loss 19196.9199, Entropy: 18977.1758, KL:  219.7438 \n",
      "Epoch [4/10], Loss 18621.2422, Entropy: 18411.8965, KL:  209.3467 \n",
      "Epoch [5/10], Loss 18940.5488, Entropy: 18722.9941, KL:  217.5538 \n",
      "Epoch [6/10], Loss 18762.9883, Entropy: 18537.1777, KL:  225.8106 \n",
      "Epoch [7/10], Loss 20092.7051, Entropy: 19881.1543, KL:  211.5514 \n",
      "Epoch [8/10], Loss 18819.5293, Entropy: 18605.9922, KL:  213.5374 \n",
      "Epoch [9/10], Loss 20054.7402, Entropy: 19841.6758, KL:  213.0651 \n",
      "Epoch [10/10], Loss 18753.1641, Entropy: 18538.4453, KL:  214.7187 \n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "outputImages = []\n",
    "train(outputImages, 'ReduceMuAndSigmaTo10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss 20004.9863, Entropy: 19821.8867, KL:  183.0988 \n",
      "Epoch [2/30], Loss 19018.4805, Entropy: 18797.4961, KL:  220.9853 \n",
      "Epoch [3/30], Loss 19471.9512, Entropy: 19246.3516, KL:  225.5994 \n",
      "Epoch [4/30], Loss 19667.0977, Entropy: 19462.9922, KL:  204.1059 \n",
      "Epoch [5/30], Loss 19061.2812, Entropy: 18829.8535, KL:  231.4277 \n",
      "Epoch [6/30], Loss 19780.3770, Entropy: 19567.8203, KL:  212.5567 \n",
      "Epoch [7/30], Loss 19608.3301, Entropy: 19416.8789, KL:  191.4513 \n",
      "Epoch [8/30], Loss 19320.1074, Entropy: 19113.2598, KL:  206.8474 \n",
      "Epoch [9/30], Loss 19605.9688, Entropy: 19384.6113, KL:  221.3566 \n",
      "Epoch [10/30], Loss 19354.1094, Entropy: 19121.4688, KL:  232.6412 \n",
      "Epoch [11/30], Loss 18275.5449, Entropy: 18041.6602, KL:  233.8850 \n",
      "Epoch [12/30], Loss 18717.7578, Entropy: 18494.1797, KL:  223.5786 \n",
      "Epoch [13/30], Loss 18065.6484, Entropy: 17843.9355, KL:  221.7128 \n",
      "Epoch [14/30], Loss 17948.4648, Entropy: 17720.8086, KL:  227.6559 \n",
      "Epoch [15/30], Loss 17964.5371, Entropy: 17741.8125, KL:  222.7249 \n",
      "Epoch [16/30], Loss 19694.8203, Entropy: 19480.9590, KL:  213.8621 \n",
      "Epoch [17/30], Loss 20087.9336, Entropy: 19846.9160, KL:  241.0185 \n",
      "Epoch [18/30], Loss 18646.0859, Entropy: 18427.7695, KL:  218.3163 \n",
      "Epoch [19/30], Loss 19208.8340, Entropy: 18978.3711, KL:  230.4632 \n",
      "Epoch [20/30], Loss 18477.3750, Entropy: 18262.6445, KL:  214.7295 \n",
      "Epoch [21/30], Loss 19022.4258, Entropy: 18797.7344, KL:  224.6913 \n",
      "Epoch [22/30], Loss 18992.9316, Entropy: 18756.0605, KL:  236.8705 \n",
      "Epoch [23/30], Loss 19807.5391, Entropy: 19574.9062, KL:  232.6320 \n",
      "Epoch [24/30], Loss 18949.2988, Entropy: 18711.6836, KL:  237.6159 \n",
      "Epoch [25/30], Loss 19119.4941, Entropy: 18903.5352, KL:  215.9586 \n",
      "Epoch [26/30], Loss 19011.4238, Entropy: 18806.3730, KL:  205.0516 \n",
      "Epoch [27/30], Loss 18498.3945, Entropy: 18288.6621, KL:  209.7323 \n",
      "Epoch [28/30], Loss 18585.0332, Entropy: 18341.7617, KL:  243.2715 \n",
      "Epoch [29/30], Loss 19641.1738, Entropy: 19413.4707, KL:  227.7033 \n",
      "Epoch [30/30], Loss 18827.1836, Entropy: 18599.2676, KL:  227.9161 \n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "outputImages = []\n",
    "train(outputImages, 'ReduceMuAndSigmaTo10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 20389.1172, Entropy: 20357.9766, KL:  31.1408 \n",
      "Epoch [2/10], Loss 20300.5684, Entropy: 20267.0430, KL:  33.5260 \n",
      "Epoch [3/10], Loss 20817.9375, Entropy: 20790.1562, KL:  27.7818 \n",
      "Epoch [4/10], Loss 21050.6875, Entropy: 21025.8633, KL:  24.8244 \n",
      "Epoch [5/10], Loss 20431.5469, Entropy: 20407.6836, KL:  23.8636 \n",
      "Epoch [6/10], Loss 20090.8750, Entropy: 20061.3945, KL:  29.4803 \n",
      "Epoch [7/10], Loss 20528.7344, Entropy: 20502.5664, KL:  26.1676 \n",
      "Epoch [8/10], Loss 20044.1172, Entropy: 20016.9336, KL:  27.1830 \n",
      "Epoch [9/10], Loss 19901.6699, Entropy: 19871.2285, KL:  30.4405 \n",
      "Epoch [10/10], Loss 20328.8809, Entropy: 20299.1719, KL:  29.7093 \n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "outputImages = []\n",
    "train(outputImages, 'Rto1AndDecoderUnfoldsCorrectly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 19340.7031, Entropy: 19067.6660, KL:  273.0374 \n",
      "Epoch [2/10], Loss 17749.2969, Entropy: 17264.1484, KL:  485.1486 \n",
      "Epoch [3/10], Loss 16665.1934, Entropy: 16013.5635, KL:  651.6296 \n",
      "Epoch [4/10], Loss 16162.4639, Entropy: 15424.8564, KL:  737.6074 \n",
      "Epoch [5/10], Loss 14840.4326, Entropy: 13837.5557, KL:  1002.8772 \n",
      "Epoch [6/10], Loss 14273.4863, Entropy: 13219.9209, KL:  1053.5653 \n",
      "Epoch [7/10], Loss 14007.1719, Entropy: 12828.5762, KL:  1178.5956 \n",
      "Epoch [8/10], Loss 14075.8506, Entropy: 12880.7725, KL:  1195.0779 \n",
      "Epoch [9/10], Loss 13558.8613, Entropy: 12396.0205, KL:  1162.8413 \n",
      "Epoch [10/10], Loss 13036.4082, Entropy: 11771.5039, KL:  1264.9047 \n"
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "outputImages = []\n",
    "train(outputImages, 'DropTo10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 12766.8984, Entropy: 11467.5771, KL:  1299.3214 \n",
      "Epoch [2/10], Loss 12961.6426, Entropy: 11648.4121, KL:  1313.2308 \n",
      "Epoch [3/10], Loss 13263.9736, Entropy: 11919.2744, KL:  1344.6991 \n",
      "Epoch [4/10], Loss 14032.5889, Entropy: 12692.1475, KL:  1340.4415 \n",
      "Epoch [5/10], Loss 13678.1377, Entropy: 12304.7334, KL:  1373.4045 \n",
      "Epoch [6/10], Loss 12761.2559, Entropy: 11373.9082, KL:  1387.3474 \n",
      "Epoch [7/10], Loss 13742.5078, Entropy: 12310.2256, KL:  1432.2817 \n",
      "Epoch [8/10], Loss 12951.0225, Entropy: 11546.1377, KL:  1404.8848 \n",
      "Epoch [9/10], Loss 13153.7861, Entropy: 11776.6826, KL:  1377.1034 \n",
      "Epoch [10/10], Loss 12787.2734, Entropy: 11379.5977, KL:  1407.6763 \n"
     ]
    }
   ],
   "source": [
    "# Model 5 - It2\n",
    "outputImages = []\n",
    "train(outputImages, 'DropTo10_IT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss 12741.8477, Entropy: 11327.5684, KL:  1414.2793 \n",
      "Epoch [2/10], Loss 12824.7891, Entropy: 11437.7178, KL:  1387.0709 \n",
      "Epoch [3/10], Loss 13878.9473, Entropy: 12441.8457, KL:  1437.1013 \n",
      "Epoch [4/10], Loss 12997.6963, Entropy: 11566.4258, KL:  1431.2701 \n",
      "Epoch [5/10], Loss 12914.2734, Entropy: 11500.6113, KL:  1413.6624 \n",
      "Epoch [6/10], Loss 13183.6943, Entropy: 11820.0420, KL:  1363.6522 \n",
      "Epoch [7/10], Loss 13298.8838, Entropy: 11929.5459, KL:  1369.3383 \n",
      "Epoch [8/10], Loss 12084.2109, Entropy: 10723.2188, KL:  1360.9922 \n",
      "Epoch [9/10], Loss 12891.9844, Entropy: 11533.6133, KL:  1358.3712 \n",
      "Epoch [10/10], Loss 13302.7559, Entropy: 11883.7832, KL:  1418.9731 \n"
     ]
    }
   ],
   "source": [
    "# Model 5 - It3\n",
    "\n",
    "outputImages = []\n",
    "train(outputImages, 'DropTo10_IT3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss 12427.7871, Entropy: 11069.5625, KL:  1358.2251 \n",
      "Epoch [2/30], Loss 12087.0352, Entropy: 10686.7334, KL:  1400.3016 \n",
      "Epoch [3/30], Loss 12625.4385, Entropy: 11244.0879, KL:  1381.3503 \n",
      "Epoch [4/30], Loss 12423.8730, Entropy: 11020.5430, KL:  1403.3303 \n",
      "Epoch [5/30], Loss 13073.8955, Entropy: 11644.2500, KL:  1429.6458 \n",
      "Epoch [6/30], Loss 13217.1074, Entropy: 11795.3018, KL:  1421.8062 \n",
      "Epoch [7/30], Loss 12549.2871, Entropy: 11161.4766, KL:  1387.8109 \n",
      "Epoch [8/30], Loss 13469.1992, Entropy: 12049.3623, KL:  1419.8367 \n",
      "Epoch [9/30], Loss 11737.7920, Entropy: 10300.0117, KL:  1437.7799 \n",
      "Epoch [10/30], Loss 12611.0391, Entropy: 11219.9668, KL:  1391.0725 \n",
      "Epoch [11/30], Loss 13148.8477, Entropy: 11735.4326, KL:  1413.4147 \n",
      "Epoch [12/30], Loss 12557.3145, Entropy: 11194.1709, KL:  1363.1440 \n",
      "Epoch [13/30], Loss 12220.1514, Entropy: 10825.6230, KL:  1394.5287 \n",
      "Epoch [14/30], Loss 12664.8535, Entropy: 11256.6191, KL:  1408.2349 \n",
      "Epoch [15/30], Loss 12764.9756, Entropy: 11320.1523, KL:  1444.8231 \n",
      "Epoch [16/30], Loss 12568.0029, Entropy: 11125.4004, KL:  1442.6023 \n",
      "Epoch [17/30], Loss 12839.1553, Entropy: 11494.1816, KL:  1344.9736 \n",
      "Epoch [18/30], Loss 12683.7578, Entropy: 11304.3652, KL:  1379.3921 \n",
      "Epoch [19/30], Loss 13008.9961, Entropy: 11537.9834, KL:  1471.0127 \n",
      "Epoch [20/30], Loss 12625.5664, Entropy: 11281.3682, KL:  1344.1984 \n",
      "Epoch [21/30], Loss 12158.5459, Entropy: 10743.8486, KL:  1414.6975 \n",
      "Epoch [22/30], Loss 12910.2588, Entropy: 11483.7500, KL:  1426.5088 \n",
      "Epoch [23/30], Loss 12210.4131, Entropy: 10793.2656, KL:  1417.1471 \n",
      "Epoch [24/30], Loss 12239.9336, Entropy: 10870.4033, KL:  1369.5308 \n",
      "Epoch [25/30], Loss 12874.7363, Entropy: 11474.3105, KL:  1400.4257 \n",
      "Epoch [26/30], Loss 13248.1494, Entropy: 11825.9600, KL:  1422.1898 \n",
      "Epoch [27/30], Loss 12560.2393, Entropy: 11152.1865, KL:  1408.0526 \n",
      "Epoch [28/30], Loss 12793.5361, Entropy: 11401.2461, KL:  1392.2897 \n",
      "Epoch [29/30], Loss 13262.0771, Entropy: 11890.8203, KL:  1371.2568 \n",
      "Epoch [30/30], Loss 12121.6729, Entropy: 10738.6797, KL:  1382.9929 \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "# Model 5 - It4\n",
    "outputImages = []\n",
    "train(outputImages, 'DropTo10_IT4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Userful resources\n",
    "# http://kvfrans.com/variational-autoencoders-explained/\n",
    "# https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "# http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
